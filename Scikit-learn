# PART 1 Scikit-learn 无监督学习

# Scikit-learn Dataset

# 加载boston房价信息示例
from sklearn.datasets import load_boston
data,target = load_boston(return_X_y=True)
print(data.shape)
print(target.shape)

# 加载手写数字库
from sklearn.datastes import load_digits
import matplotlib.pyplot as plt
digits = load_digits()
plt.matshow(digits.images[3])
plt.show()

# 采用kmeans进行聚类操作，数据为31个身份居民家庭平均支出，包含8个维度数据，对于31个省份进行聚类。
from sklearn.cluster import KMeans
from sklearn.datasets import load_iris

if __name__ = '__main__':
    # import iris data:x is iris feature and y is the class
    x,y = load_iris(return_X_y=True)
    # the number clusters is 3
    km = KMeans(n_clusters = 3,init='K-means++',max_iter=10000)
    label = km.fit_predict(x)
    # evaluate the accuracy
    error_cnt = 0
    sum_cnt = 0
    for i in range(len(label)):
        if (y[i] != label[i]):
            error_cnt = error_cnt + 1
        sum_cnt = sum_cnt + 1
    print("Error rate:%.2f" % (error_cnt/sum_cnt))
    
''' 
kmeans可以用于图像分割，即利用图像分灰度、颜色、纹理、形状等特征将图像分为若干不重叠区域，使这些特征在同一区域具有相似性而不同区域呈现冥想差异性。
图像分割常用技术包括了阈值分割、边缘分割、直方图法和聚类分析、小波变换等。kmeans分割可以实现图像中相似特征聚类，从而完成分割情况。
对于同一类采用相同颜色标记，最终可以形成分割图像。实例如下，一个较重要的包为PIL，实例代码如下：
'''
import PIL.Image as image
def loadData(filePath):
    f = open(filePath,'rb')
    data = []
    img = image.open(f)
    m,n = img.size
    for i in range(m):
        for j in range(n):
            x,y,z = img.getpixel((i,j))
            data.append([x/256.0,y/256.0,z/256.0]}
    f.close()
    return np.mat(data),m,n

'''
聚类之DBSCAN方法使用:
算法流程如下所示，第一步包括了计算每一个点邻域eps距离内的点，超过minpts个数，则记该点为核心点；然后查看剩余点是否在邻域内，如果在则为邻域点；否则为噪声点。
第二步为删除噪声点；
第三步为连接距离在eps内的核心点，构成一个簇；
第四步，指定边界点归类于哪一个簇。
'''
# 统计每一类别元素个数的代码
for i in range(0,nc):
    number0fClass.append(len(label[label[:] == i]))
print(number0fClass)

#统计分类个数的代码
n_clusters = len(ste(labels))-(1 if -1 in labels else 0)

# DBSCAN 核心代码
db = DBSCAN(eps=1,min_samples=20).fit(x)
labels = db.labels_

'''
采用PCA可以对于iris数据集进行降维操作
'''
# 原数据为四维的，使用PCA对数据进行降维。实现在二维平面的可视化
import matplotlib.pyplot as plt
from skleran.decomposition import PCA
from sklearn.datasets import load_iris
# 导入数据,以字典形式加载数据集
data = load_iris()
# y表示数据集中的标签
y = data.target
# x表示数据集中的属性数据
X = data.data
# 加载PAC算法，主成分数目为2
pca = PCA(n_components=2)
# 对原始数据进行降维，保存在reduce_X中
reduced_X = pac.fit_transform(X)
# 按类别将降维后的数据进行保存
red_x,red_y = [],[]
blue_x,blue_y = [],[]
green_x,green_y = [],[]

# 按照鸢尾花的类别将降维后的数据点保存在不同的列表中
for i in range(len(reduced_X)):
    if y[i] == 0:
        red_x.append(reduced_X[i][0])
        red_y.append(reduced_X[i][1])
    elif y[i] == 1:
        blue_x.append(reduced_X[i][0])
        blue_y.append(reduced_X[i][1])
    else:
        green_x.append(reduced_X[i][0])
        green_y.append(reduced_X[i][1])
# 画x关于y的散点图
plt.scatter(red_x,red_y,c='r',marker='X')
plt.scatter(blue_x,blue_y,c='b',marker='D')
plt.scatter(green_x,green_y,c='b',marker='.')
plt.show()

# PART 2 Scikit-learn 监督学习
# KNN分类
from sklearn.neighbors import KNeighborsClassfier
x = [[0],[1],[2],[3]]
y = [0,0,1,1]

neigh = KNeighborsClassifier(n_neighbor=3)
neigh.fit(x,y)

print(neigh.predit([[1.1]]))

# 决策树分类
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_validate
#默认使用gini分类，这里采用entropy分类
clf = DecisionTreeClassifier(criterion='entropy')
iris = load_iris()
print(cross_validate(clf,iris.data,iris.target,cv=10))

# 朴素贝叶斯分类
import numpy as np
from sklearn.naive_bayes import GaussianNB
X = np.array([[-1,-1],[-2,-1],[-3,-2],[1,1],[2,1],[3,2]])
Y = np.array([1,1,1,2,2,2])
clf = GaussianNB(priors=None)
clf.fit(X,Y)
print(clf.predict([[-0.8,-1]]))

# SVM分类
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_validate
from sklearn import svm
clf = svm.SVC(kernel='rbf')
x,y = load_iris(return_X_y=True)
print(cross_validate(clf,x,y,cv=10))

# MLP分类
clf = MLPClassifier(hidden_layer_sizes=(100,),
                    activation='logistic', solver='adam',
                    learning_rate_init = 0.0001, max_iter=2000)
print(clf)
clf.fit(train_dataSet,train_hwLabels)

#read  testing dataSet
dataSet,hwLabels = readDataSet('testDigits')
res = clf.predict(dataSet)   #对测试集进行预测

# PART 3 Scikit-learn 回归
# 线性回归/多项式回归
from sklearn.prepocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree = 2)
X_poly = poly_reg.fit_transform(datasets_X)
lin_reg_2 = linear_model.LinearRegression()
lin_reg_2.fit(X_poly, datasets_Y)
